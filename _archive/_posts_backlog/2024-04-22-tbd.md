---
layout: post
title:  "Relevance of transformer models in healthcare"
author: sandy
categories: [ healthcare, EHR, AI ]
image: assets/images/2024-03/iStock-1025882206_license.jpg
featured: false
hidden: false
---

Some recent studies[] have made it into the media highlighting limitations of LLMs, perhaps casting a shadow on the true potential of generative AI.  As I've written before, healthcare is arguably at an inflection point where innovation is needed, but in the right places.  As a business leader or technologist, I think its important to ask:  In what ways are these AI models superior to their predecessors?  What are the most applicable use cases?  In this post, I take a deeper look into healthcare applications using transfomer models, and evaluate their usefulness in healthcare.

## A primer on transformer models
There is no shortage of resources to learn about transformer models such as GPT, and I will not go into the details here.  However, I found this [tutorial](https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0) particularly intuitive in understanding transformers, and it serves as a good backdrop for their application in healthcare. 

At a high-level, transfomer models make use of the [attention mechanism](https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html), which one can think of as a computer's ability to focus on specific parts of input text to accomplish a specific ML task.  A specific type of mechanism, called [self-attention](https://arxiv.org/abs/1706.03762), enables a computer to mathematically weigh the importance between different words in a sentence.    

Here is a nice visual of how attention mechanism works:

[image]

The result of this technique has overcome the limitation of previous NLP models such as LTSM and RNN

computer's ability to retain meaning of longer text sequences.


Next, let's visualize how transformers best RNN and LTSM architectures.  



## Limitations of existing NLP models in healthcare
I'm sure we can now see how existing NLP architectures 

## Experiments using transformers in healthcare
Now that we have understood the how transformers have succeeeded over previous NLP architectures.


## Why are transformers so powerful in healthcare?

## Conclusion

## References
+ <https://www.datacamp.com/tutorial/how-transformers-work>
+ https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0
+ https://dzone.com/articles/a-deep-dive-into-the-transformer-architecture-the
+ <https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html>