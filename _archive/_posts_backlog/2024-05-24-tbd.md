---
layout: post
title:  "The med-mal debate in the era of generative AI"
author: sandy
categories: [ healthcare, EHR, AI ]
image: assets/images/2024-03/iStock-1025882206_license.jpg
featured: false
hidden: false
---

I have not delved into AI ethics as of late, but this [article](https://www.politico.com/news/2024/03/24/who-pays-when-your-doctors-ai-goes-rogue-00148447) sheds light into the on-going debate of accountability when AI is used for patient care.  Should clinicians ultimately be on the hook?  What role do regulators play?  Should tech companies register AI tools as SaMD?  In this post, I explore the current discussions around these questions and recommended paths going forward.  

## Figuring out who makes the final call

Should AI become SaMD (software as a medical device)?  This recent [article](https://www.politico.com/news/2024/03/24/who-pays-when-your-doctors-ai-goes-rogue-00148447) calls upon this question as regulators, patients, and physicians assess the risk the technology poses to such stakeholders.   

 a bit about  What's the right approach to regulate AI in healthcare?  There has certainly been much discussion over the past year, but I had not really seen much discussion as far as *who* gets the blame when there is a mistake.  In this fascinating read from 

## A primer on transformer models










## Conclusion



## References
+ <https://www.datacamp.com/tutorial/how-transformers-work>
https://www.politico.com/newsletters/future-pulse/2024/05/17/a-leader-for-the-ai-skeptics-00158592
https://www.politico.com/newsletters/politico-pulse/2024/02/20/the-fdas-ai-quandary-00142114
https://www.statnews.com/2024/02/07/ai-assurance-laboratories-onc-fda-equity/
https://journalofethics.ama-assn.org/issue/artificial-intelligence-health-care