---
layout: post
title:  "Black box algorithms: Are they a problem?"
author: sandy
categories: [ AI, healthcare ]
image: assets/images/2023-08/healthcare-is-keeping-the-fax-machine-alive.png
---
After writing my last post, I was intrigued to learn a bit more about the black box phenomenon in AI models.  More pressing is understanding their implication for healthcare (perceived vs. actual).  This is not to say that AI has not already been embedded into medical products today, judging by the increasing number of FDA-approved AI algorithms.  However, I think it is important to understand the distinction of the algorithms embedded into such products.  In this post, I aim to provide a technical lens into this topic.  

## A database of FDA-approved AI algorithms
For those that are not aware, the FDA regularly tracks and publishes [AI/ML-enabled medical devices](https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices) that have gained regulatory approval.  Fortunately, I was also able to dig up a 2020 article in [Nature](https://www.nature.com/articles/s41746-020-00324-0) which organizes these device algorithms into a database.  Although it looks like it has not been updated since mid-2021, it is still a good reference point.  First, let's take a look at the categories by which the FDA approves such devices:

[insert image]

In reviewing this [database](https://medicalfuturist.com/fda-approved-ai-based-algorithms), I decided to focus on algorithms focused on cardiology.  Eko Devices Inc. developed the Eko Analysis Software (EAS), which was approved by the FDA on January 15, 2020.  According to their [summary](https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpmn/pmn.cfm?ID=K192004) document, the tool is described as follows:

>The Eko Analysis Software is a cloud-based software API that allows a user to upload
synchronized ECG and heart sound/phonocardiogram (PCG) data for analysis. The software
uses several methods to interpret the acquired signals including signal processing and artificial
neural networks. The API can be electronically interfaced, and perform analysis with data
transferred from multiple mobile or computer based applications. 

I will focus on the neural networks component.  

## Discriminative vs. Generative models
Before I dive into discriminative and generative models, it was helpful for me to review the main approaches for handling machine learning tasks: supervised and unsupervised learning.  

At a high level, supervised learning uses inputs (x) and outputs (y) to fit a model.  Here, the machine algorithm learns the best mapping function from input ("labeled data") to output ("labels").  

![supervised](/assets/images/2024-06/supervised.png){:.centered}

{:.image-caption}
*Credit: Denecke, K., May, R. & Rivera-Romero, O. Transformer Models in Healthcare: A Survey and Thematic Analysis of Potentials, Shortcomings and Risks. J Med Syst 48, 23 (2024).  Used under [CC BY 4.0.](https://creativecommons.org/licenses/by/4.0)*

In contrast, unsupervised learning has no labeled inputs nor outputs.  Here, the machine learning algorithm learns the best mapping function that finds similarity among the input samples, and groups them based on that similarity as the output.  

![unsupervised](/assets/images/2024-06/unsupervised.png){:.centered}


The models that fall under each approach can be generally categorized as [discriminative or generative](https://www.turing.com/kb/generative-models-vs-discriminative-models-for-deep-learning).  By discriminative, the model aims to separate data points into different classes and learn the decision boundaries.  By generative, the model aims to generate new data points similar to the data it was trained on:

![gen_disc_model-1](/assets/images/2024-06/gen_disc_model-1.png){:.centered}

Mathematically*, we tend to see discriminative models used in supervised learning, where the goal is to learn a mapping between an input and output variable.  Generative models are typically used in unsupervised learning, where the goal is to learn the underlying probability distribution of the data:

![discriminative_generative2](/assets/images/2024-06/discriminative_generative2.png){:.centered}

https://www.adventuresinmachinelearning.com/generative-vs-discriminative-models-understanding-the-differences/#:~:text=Discriminative%20models%20are%20typically%20used%20in%20supervised%20learning,learn%20the%20underlying%20probability%20distribution%20of%20the%20data.

*For a deeper dive, see the [Supervised Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning) by Afshine Amidi and Shervine Amidi from Stanford.

Neural networks can be considered an example of generative models, although in my research this categorization is not [mutually exclusive](https://stats.stackexchange.com/questions/403968/linking-generative-discriminative-models-to-supervised-and-unsupervised-learnin) and is often based on the specific use case.  For example, neural networks can be

In the case of Eko... https://support.ekohealth.com/hc/en-us/articles/13180195624347-Eko-App-FAQ

# The neural network is a black box, and I'm worried
In reviewing the theory behind neural networks as a generative model, I see the valid concern that it is a black box.  If one considers that neural network architectures (specifically the transformer architecture) is forming the basis of nearly every generative AI application on the market today, could this spell trouble for healthcare?

https://stats.stackexchange.com/questions/93705/why-are-neural-networks-described-as-black-box-models

https://news.mit.edu/2022/machine-learning-explainability-0505#:~:text=Modern%20machine-learning%20models%2C%20such%20as%20neural%20networks%2C%20are,them%20can%E2%80%99t%20fully%20understand%20how%20they%20make%20predictions.

https://www.techtarget.com/healthtechanalytics/feature/Navigating-the-black-box-AI-debate-in-healthcare
## Is there value in explainable AI?

## Conclusion

I appreciated this insightful and hopeful article for the future of healthcare.  Perhaps with this new wave of AI, there is a renewed commitment by people and processes to enable a better healthcare experience for everyone.  Finally, may we put that old fax machine to rest.