---
layout: post
title:  "Switchover disruptions: The true cost of a medical scribe"
author: sandy
categories: [ healthcare, AI, economics ]
image: assets/images/2023-10/shutterstock_1841040424_license_resize.png
---
"Switchover disruptions" were highlighted in Harvard Business Review's recent [article](https://hbr.org/2023/09/ai-adoption-in-u-s-health-care-wont-be-easy) on the challenges of AI adoption in healthcare.  [Economists](https://www.aeaweb.org/articles?id=10.1257/mic.4.3.1) define it as the cost of integrating new technologies that can dampen an organization's profits.

This prompted me to examine the ways in which this new wave of AI (Large Language Models) can minimize such disruptions, and if this type of AI is worth the tradeoff.  

## The unsettling case of high switchover disruption: EHRs

I was fascinated by the article's comparison of 2 new technologies that arrived in healthcare: EHRs vs. new surgical technique to remove the gallbladder.  EHRs faced strong resistance, until the Obama administration stepped in to [incentivize](https://www.hipaajournal.com/what-is-the-hitech-act/#:~:text=The%20HITECH%20Act%20was%20created%20to%20promote%20and,%28HIPAA%29%20by%20tightening%20up%20the%20language%20of%20HIPAA.) organizations to go digital.  The new (minimally invasive) surgical technique faced a low switchover disruption - physician adoption was easier.  

The key?  Hospitals and surgeons were *already in the business* of removing gallbladders.

EHRs should have been an easy win.  Why wouldn't a patient want to see all their medical information stored in one place?  Why wouldn't a physician want to see a more complete view of their patient's health?  In all other industries where digitization has led to improved efficiency, the complete opposite happened with EHRs.  Perhaps we were not aligned on improving healthcare outcomes after all.

I agree that the issue came down to control.  Not surprisingly (in a capitalist society), there are power struggles between physicians, payers, and government.  But guess who loses out in the end?  The patient.  

Will the same fate await this next wave of AI?

## The most plausible genAI use case: Medical Scribe

The arrival of chatGPT has created a dizzying revival for using AI in healthcare, with the promise of automated diagnosis and treatments.  This, by the way, were the same statements touted by [IBM Watson](https://spectrum.ieee.org/how-ibm-watson-overpromised-and-underdelivered-on-ai-health-care) a decade ago.  Granted that today's AI technology has improved over its predecessors, that doesn't matter unless it can prove its business value.  "Prove to me that it will actually do something useful—that it will make my life better, and my patients' lives better.", stated Martin Kohn (former IBM Research chief medical scientist), and that still rings true today.

Today's AI systems can do something useful - work as a medical scribe.  Unfortunately, one of the ill by-products of digitization has been increased [administrative burden](https://www.medicaleconomics.com/view/top-challenges-2021-1-administrative-burdens-and-paperwork) placed upon healthcare providers.  If a technology can help reduce this burden by summarizing patient information or answering patient questions efficiently, providers will have more face-to-face time with patients, and increase productivity.  For example, [JAMA](https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2804309) reported that an AI chatbot assistant (ChatGPT) was found to provide quality and empathetic responses to patient questions found in an online forum.  I think more physicians would be on board with these technologies, as they could make a practice/health system more profitable.

Although this is less glamorous than diagnosing and treating patients, I think this is probably the best place for AI.  It may be the only place where AI can properly function, without jeopardizing the existing power dynamics among health entities and the government.  


## The true cost of running LLMs

While these next-gen AI models (LLMs) have demonstrated remarkable performance in terms of human comprehension, one must also consider the ROI to run them.  They are not cheap, due to the amount of data they can process and the compute power required.  The Wall Street Journal ran a [piece](https://www.wsj.com/tech/ai/ais-costly-buildup-could-make-early-products-a-hard-sell-bdd29b9f) earlier this month on the struggles for tech giants to monetize these technologies.  According to the article, Microsoft is using OpenAI’s latest version (GPT-4) software for its AI features.  However, that version is the largest and most expensive model available.  

Equally important is understanding the technology's impact on the environment.  According to this Ars Tehnica [op-ed](https://arstechnica.com/gadgets/2023/04/generative-ai-is-cool-but-lets-not-forget-its-human-and-environmental-costs/), the most expensive and proprietary ("black box") models are reserved for very deep pocketed organizations.  As such,  building and deploying these models "requires a lot of planetary resources: rare metals for manufacturing GPUs, water to cool huge data centers, energy to keep those data centers running 24/7 on a planetary scale… all of these are often overlooked in favor of focusing on the future potential of the resulting models."

What's the right ROI then?  Would it behoove healthcare organizations to use smaller, open-source LLMs?  Certainly, a lack of privacy standards should be of upmost concern.  However, it might be overkill to use the likes of GPT-4 and beyond to answer patient questions.  Perhaps the sweet spot could lie with patient summarization and triaging tasks.

One must consider the tradeoff in terms of time/cost for leveraging human labor vs. a turbo-charged AI chatbot.


## Conclusion

I appreciated this article's insights into the challenges of AI adoption in healthcare.  The challenges were no different a decade ago with EHR adoption, and it was very interesting to understand the power dynamics that made adoption difficult.  I think these next-gen AI technologies have seen a bit more acceptance by the healthcare community, and if it can align with the way hospitals and physicians already do business, adoption could really take off.  I think the jury is still out as far as how sophisticated AI should be, with a medical scribe feeling like a safe bet.