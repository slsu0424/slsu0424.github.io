---
layout: post
title:  "Chat with healthcare data in natural language: LLMs with LangChain"
author: sandy
categories: [ ChatGPT, NLP, tutorial ]
image: assets/images/2023-10/shutterstock_2188258735_license_resize.png
---
What is today's value in chatting with healthcare data?  After all, NLP has been around for a long time.  What makes GenAI different?  

This was a topic that I explored back in September, where I presented the 2nd iteration of my talk on Large Language Models (LLMs).  This time I had a chance to go a bit deeper into two examples that covered integrating LLMs with LangChain, and LLMs with SQL.  

This tutorial accompanies the first example: LLMs and LangChain to chat with a healthcare document.


Pre-requisites:
1. Intermediate knowledge of OpenAI
3. Python 3.11

All resources can be found [here](https://github.com/slsu0424/pmc-patients).

## Generate an ADE report

For the first step, I used OpenAI's ChatGPT (GPT-3.5) to generate a synthetic adverse events report for warfarin.  I chose warfarin as it is in the class of drugs that have resulted in [serious adverse drug reactions](https://www.ncbi.nlm.nih.gov/books/NBK519025/).

These were the series of prompts I used to generate the final [output]():

"Create an adverse event report related to warfarin.  Limit to 250 words."  
"Remove the Reporting Authority section"  
"expand to 500 words"  
"Include the Reporting Authority section"  

A snippet of the document is below:

>On October 20, 2023, at 09:30 AM, the patient, John Doe, experienced a significant adverse event related to the anticoagulant medication warfarin. Mr. Doe, a 68-year-old male with a history of atrial fibrillation, had been taking warfarin (5 mg daily) for the past three years as prescribed by his cardiologist.

## Q&A application overview

This [blog post](https://github.com/hwchase17/chat-your-data/blob/master/blogpost.md) by LangChain's founder, Harrison Chase, provides a high-level overview for building a text-based Q&A application.  

The main steps include:

1. Load documents
2. Split documents into chunks
3. Create embedding vectors from chunks
4. Store vectors in vector database
5. Retrieve relevant documents from database
6. Pass relevant documents to LLM
7. LLM generates final answer

Ingest Data:

![langchain1](/assets/images/2023-10/langchain1.png)

Query Data:

![langchain2](/assets/images/2023-10/langchain2.png)


## Use LangChain to load documents into a vector store
[Langchain](https://docs.langchain.com/docs/) is a framework for developing applications powered by LLMs, like the one above.  The main idea is that developers can "chain" different components around an LLM to create more powerful use cases.  

Hence, we can "chain" an LLM to another component, such as a document.

LangChain has many different methods to load documents.  We easily use the **PyPDFLoader** to load in the PDF document and create a vector representation using the **VectorStoreIndexCreator**:

```python
# Load PDF document
loaders = PyPDFLoader('/Users/sandysu/Documents/GitHub/OpenAI/docs/ADR11.pdf')

# Create a vector representation of the loaded document
index = VectorstoreIndexCreator().from_loaders([loaders])
```

The VectorStoreIndexCreator handles steps 2-4 above (chunking, embedding, and storage).  This [article](https://medium.com/@kbdhunga/enhancing-conversational-ai-the-power-of-langchains-question-answer-framework-4974e1cab3cf) goes into more detail about the class, including customization.  

The default settings to note are: 

- Chunking - uses **RecursiveCharacterTextSplitter()** to divide text at specific characters
- Embedding - uses **OpenAIEmbeddings**  to generate embeddings
- Storage - embeddings are stored in **Chroma**, an open-source vector store 

## Set up Streamlit app to query document
Next, we set up a simple UI to allow users to ask questions of the ADE document.  

```python
# Display the page title and the text box for the user to ask the question
st.title('ðŸ¦œ Query your PDF document ')
prompt = st.text_input("Enter your question to query your PDF documents")
```

## Query the vector store
When a user passes in a question, the store is queried to retrieve the data that is 'most similar' to the embedded query.

```python
response = index.query(llm=OpenAI(model_name="gpt-3.5-turbo", temperature=0.2), question = prompt, chain_type = 'stuff')
```

Under the hood, we pass in the OpenAI model (gpt-3.5-turbo), and set the [temperature](https://platform.openai.com/docs/guides/gpt/how-should-i-set-the-temperature-parameter).  The temperature controls the randomness of the output generated by the model.  For example, a temperature value closer to 1 will generate a more creative response.  For [chain_type = 'stuff'](https://python.langchain.com/docs/modules/chains/document/stuff), this will combine multiple input documents into a single prompt to pass to an LLM.

This visual shows the workflow in more detail:

<a href="https://python.langchain.com/docs/modules/data_connection/vectorstores/#:~:text=One%20of%20the%20most%20common%20ways%20to%20store,that%20are%20%27most%20similar%27%20to%20the%20embedded%20query">
  <img src="/assets/images/2023-10/langchain3.png" alt="langchain3" width="750" height="311">
</a>


## Let's ask some questions
With the Streamlit app loaded, we can ask a question of the ADE document:





## Conclusion

In this tutorial, we explored how to create word embeddings from scratch, using a neural network to perform a classification task.  By taking sample text from PubMed patient summaries, we were able to train a neural network to classify patients who had COVID-19 and those that did not.  In doing so, we were also able to train the embeddings, such that words with similar meanings were visually placed closer together.  

We can boost the performance of the training accuracy by adding in a different layer, such as a convolution layer.  I will explore these in future posts.


## References
+ <https://medium.com/technology-hits/overview-of-langchain-9f6362707cd0>
+ <https://towardsai.net/p/machine-learning/chat-with-your-healthcare-documents-build-a-chatbot-with-chatgpt-and-langchain>

https://www.techsmartfuture.com/chunking-natural-language-processing/
https://towardsdatascience.com/how-to-chunk-text-data-a-comparative-analysis-3858c4a0997a
https://api.python.langchain.com/en/latest/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html

https://www.wwt.com/blog/a-brief-history-of-nlp
https://dspace.mit.edu/bitstream/handle/1721.1/150502/2023_NLP_JPM.pdf?sequence=1&isAllowed=y

https://www.analyticsvidhya.com/blog/2022/07/the-evolution-of-nlp-from-1950-to-2022/