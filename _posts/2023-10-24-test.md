---
layout: post
title:  "Chatting with healthcare data in natural language"
author: sandy
categories: [ ChatGPT, NLP, tutorial ]
image: assets/images/2023-09/shutterstock_1025566351_license_resize.png
---
In September, I had the opportunity to deliver the 2nd iteration of my talk on LLMs, LangChain, and SQL.  This time I had a chance to go a bit deeper into the demos I had set up.  I have written the below tutorial (including code) to accompany the demos shared in that talk.  

This tutorial will cover 2 examples:

1) Use LLMs with LangChain to chat with a healthcare document
2) Use LLMs with SQL to chat with the MIMIC-III database

All resources can be found [here](https://github.com/slsu0424/pmc-patients).

## What's the value of chatting with data?

Healthcare is inudated with data - much of it in unstructured formats such as EHR notes, radiology images, to fitness wearables that generate real-time data.  Focusing on the former, there is a wealth of knowledge buried in pages upon pages of written text.  How can we access that one piece of crucial information?

Processing lengthy documents are nothing new for computers, as we could ingest documents into a cloud data store, manipulate the data to put it in a structured format, and make it available for downstream querying.  A search engine could be deployed on top of the data, but could have mixed results.  For example, the user may have to be more explicit in their query statement.

What if you could easily chat with this document using natural language?  What if the engine could better understand your intent?

https://www.jointcommission.org/-/media/tjc/documents/standards/r3-reports/r3_19_anticoagulant_therapy_rev_final1.pdf?db=web&hash=7C6FA69A5DF9294B7BADF2B52C653FCA

https://www.ncbi.nlm.nih.gov/books/NBK519025/?report=reader

https://www.ncbi.nlm.nih.gov/books/NBK519025/

## What is LangChain?

Langchain is a framework for developing applications powered by Large Language Models (LLMs).  It was launched as an open source project in October 2022.  The main idea is that developers can "chain" different components around an LLM to create more powerful use cases.  

Hence, we can "chain" an LLM to another component, such as a document.

## Example 1: Use LLMs with LangChain to chat with a healthcare document 

We use OpenAI's ChatGPT (GPT-3.5) to generate a synthetic adverse events report for warfarin, which has a high-risk of adverse outcomes.  A snippet of the document is below:

>**Description of Adverse Event:**
On October 20, 2023, at 09:30 AM, the patient, John Doe, experienced a significant adverse event related to the anticoagulant medication warfarin. Mr. Doe, a 68-year-old male with a history of atrial fibrillation, had been taking warfarin (5 mg daily) for the past three years as prescribed by his cardiologist.


LangChain has many different document loaders.  Very easily, we will use PyPDFLoader to load this PDF document and create a vector representation:

```python
# Load PDF document
loaders = PyPDFLoader('/Users/sandysu/Documents/GitHub/OpenAI/docs/ADR11.pdf')

# Create a vector representation of the loaded document
index = VectorstoreIndexCreator().from_loaders([loaders])
```

## A word about Vector Store




For 100 documents, there are 2451 total words in the corpus.


## Convert text to integers

Since we saw the limitations with one-hot encoding, a better approach would be to assign each word a unique integer.  The integer encoding for a specific word remains the same across all documents, so this will reduce the size of the corpus to unique words. 

To do this, Keras (neural network library) provides a handy **Tokenizer() API** that can handle multiple documents.  For a deeper understanding of its implementation, see this [tutorial](https://machinelearningmastery.com/prepare-text-data-deep-learning-keras).


![](/assets/images/2023-09/output2.png)

## Conclusion

In this tutorial, we explored how to create word embeddings from scratch, using a neural network to perform a classification task.  By taking sample text from PubMed patient summaries, we were able to train a neural network to classify patients who had COVID-19 and those that did not.  In doing so, we were also able to train the embeddings, such that words with similar meanings were visually placed closer together.  

We can boost the performance of the training accuracy by adding in a different layer, such as a convolution layer.  I will explore these in future posts.


## References
+ <https://medium.com/technology-hits/overview-of-langchain-9f6362707cd0>
