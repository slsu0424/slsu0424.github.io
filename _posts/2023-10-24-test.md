---
layout: post
title:  "Chatting with healthcare data in natural language"
author: sandy
categories: [ ChatGPT, NLP, tutorial ]
image: assets/images/2023-10/shutterstock_2188258735_license_resize.png
---
In September, I had the opportunity to present the 2nd iteration of my talk on Large Language Models (LLMs).  This time I had a chance to go a bit deeper into the demos that covered integrating LLMs with LangChain, and LLMs with SQL.  I have written this tutorial to accompany these demos.    

This tutorial will cover 2 examples:

1) Use LLMs with LangChain to chat with a healthcare document  
2) Use LLMs with SQL to chat with the MIMIC-III database

All resources can be found [here](https://github.com/slsu0424/pmc-patients).

## What's the value of chatting with data?

Healthcare is inundated with data - much of it is in unstructured formats such as EHR notes, radiology images, medical device readings, and even consumer fitness wearables.  Focusing on the former, there is a wealth of knowledge buried in pages upon pages of written text.  From a clinical perspective, how can relevant information be retrieved quickly without explicit programming?

While NLP techniques have been used [since the 1950s](https://en.wikipedia.org/wiki/Natural_language_processing) to process and generate text, the ability to generate text with human-like accuracy is extremely [powerful](https://news.mit.edu/2023/ai-models-astrocytes-role-brain-0815).  

What if you could easily chat with data using natural language prompts?  What if the AI system could better understand your intent?

## Example 1: Use LLMs with LangChain to chat with a healthcare document 

#### 1. Generate an ADE report

I used OpenAI's ChatGPT (GPT-3.5) to generate a synthetic adverse events report for warfarin.  I chose warfarin as it is in the class of drugs that have resulted in [serious adverse drug reactions](https://www.ncbi.nlm.nih.gov/books/NBK519025/).  Hence, there would be more internet information on warfarin that would be fed into the model.   

These were the series of prompts I used to generate the final output:

"Create an adverse event report related to warfarin.  Limit to 250 words."  
"Remove the Reporting Authority section"  
"expand to 500 words"  
"Include the Reporting Authority section"  

A snippet of the document is below:

>On October 20, 2023, at 09:30 AM, the patient, John Doe, experienced a significant adverse event related to the anticoagulant medication warfarin. Mr. Doe, a 68-year-old male with a history of atrial fibrillation, had been taking warfarin (5 mg daily) for the past three years as prescribed by his cardiologist.

*Note:* LLMs can generate [different answers for the same prompt](https://ai.stackexchange.com/questions/32385/why-do-language-models-produce-different-outputs-for-same-prompt) due to the stochastic nature of predicting the next word.  For example, I tried this single prompt:

"Create an adverse event report related to warfarin.  Limit to 500 words." 

which returned an entirely different [output]().

#### 2. Use LangChain to load documents into a vector store

Langchain is a framework for developing applications powered by LLMs.  It was launched as an open source project in October 2022.  The main idea is that developers can "chain" different components around an LLM to create more powerful use cases.  

Hence, we can "chain" an LLM to another component, such as a document.

LangChain has many different document loaders.  Very easily, we can use **PyPDFLoader** to load in the PDF document and create a vector representation:

```python
# Load PDF document
loaders = PyPDFLoader('/Users/sandysu/Documents/GitHub/OpenAI/docs/ADR11.pdf')

# Create a vector representation of the loaded document
index = VectorstoreIndexCreator().from_loaders([loaders])
```

According to LangChain, the class [VectorstoreIndexCreator](https://api.python.langchain.com/en/latest/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html) creates a vectorestore index from loaders.  By vectorstore index, this means 


https://medium.com/@kbdhunga/enhancing-conversational-ai-the-power-of-langchains-question-answer-framework-4974e1cab3cf


## Example 2: Use LLMs with SQL to chat with the MIMIC-III database

Since we saw the limitations with one-hot encoding, a better approach would be to assign each word a unique integer.  The integer encoding for a specific word remains the same across all documents, so this will reduce the size of the corpus to unique words. 

To do this, Keras (neural network library) provides a handy **Tokenizer() API** that can handle multiple documents.  For a deeper understanding of its implementation, see this [tutorial](https://machinelearningmastery.com/prepare-text-data-deep-learning-keras).


![](/assets/images/2023-09/output2.png)

## Conclusion

In this tutorial, we explored how to create word embeddings from scratch, using a neural network to perform a classification task.  By taking sample text from PubMed patient summaries, we were able to train a neural network to classify patients who had COVID-19 and those that did not.  In doing so, we were also able to train the embeddings, such that words with similar meanings were visually placed closer together.  

We can boost the performance of the training accuracy by adding in a different layer, such as a convolution layer.  I will explore these in future posts.


## References
+ <https://medium.com/technology-hits/overview-of-langchain-9f6362707cd0>
+ <https://towardsai.net/p/machine-learning/chat-with-your-healthcare-documents-build-a-chatbot-with-chatgpt-and-langchain>
