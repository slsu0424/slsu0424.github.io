---
layout: post
title:  "Chatting with healthcare data in natural language"
author: sandy
categories: [ ChatGPT, NLP, tutorial ]
image: assets/images/2023-10/shutterstock_2188258735_license_resize.png
---
In September, I had the opportunity to present the 2nd iteration of my talk on Large Language Models (LLMs).  This time I had a chance to go a bit deeper into the demos that covered integrating LLMs with LangChain, and LLMs with SQL.  I have written this tutorial to accompany the demos.    

This tutorial will cover 2 examples:

1) Use LLMs with LangChain to chat with a healthcare document  
2) Use LLMs with SQL to chat with the MIMIC-III database

All resources can be found [here](https://github.com/slsu0424/pmc-patients).

## What's the value of chatting with data?

Healthcare is inundated with data - much of it is in unstructured formats such as EHR notes, radiology images, medical device readings, and even consumer fitness wearables.  Focusing on the former, there is a wealth of knowledge buried in pages upon pages of written text.  How can we access that one piece of crucial information?

Processing lengthy documents are nothing new for computers, as we could ingest documents into a cloud data store and make it available for downstream querying.  A search engine could be deployed on top of the data, but could have mixed results.  For example, the user may have to be explicit in their query statement to retrieve the correct information.

What if you could easily chat with this document using natural language?  What if the engine could better understand your intent?

## What is LangChain?

Langchain is a framework for developing applications powered by LLMs.  It was launched as an open source project in October 2022.  The main idea is that developers can "chain" different components around an LLM to create more powerful use cases.  

Hence, we can "chain" an LLM to another component, such as a document.

## Example 1: Use LLMs with LangChain to chat with a healthcare document 

# Gemerate an ADE report
I used OpenAI's ChatGPT (GPT-3.5) to generate a synthetic adverse events report for warfarin.  I chose warfarin as it is in the class of drugs that have resulted in [serious adverse drug reactions](https://www.ncbi.nlm.nih.gov/books/NBK519025/).  Hence, there would be more internet information on warfarin that would be fed into the model.   

These were the series of prompts I used to generate the final output:

"Create an adverse event report related to warfarin.  Limit to 250 words."  
"Remove the Reporting Authority section"  
"expand to 500 words"  
"Include the Reporting Authority section"  

A snippet of the document is below:

>On October 20, 2023, at 09:30 AM, the patient, John Doe, experienced a significant adverse event related to the anticoagulant medication warfarin. Mr. Doe, a 68-year-old male with a history of atrial fibrillation, had been taking warfarin (5 mg daily) for the past three years as prescribed by his cardiologist.

*Note:* LLMs can generate [different answers for the same prompt](https://ai.stackexchange.com/questions/32385/why-do-language-models-produce-different-outputs-for-same-prompt) due to the stochastic nature of predicting the next word.  For example, I tried the below prompt:

"Create an adverse event report related to warfarin.  Limit to 500 words." 

and got an entirely different [output]().

# Use LangChain to load documents into a vector store
LangChain has many different document loaders.  Very easily, we can use **PyPDFLoader** to load in the PDF document and create a vector representation:

```python
# Load PDF document
loaders = PyPDFLoader('/Users/sandysu/Documents/GitHub/OpenAI/docs/ADR11.pdf')

# Create a vector representation of the loaded document
index = VectorstoreIndexCreator().from_loaders([loaders])
```

## Vector Store

According to LangChain, the class [VectorstoreIndexCreator](https://api.python.langchain.com/en/latest/indexes/langchain.indexes.vectorstore.VectorstoreIndexCreator.html) creates a vectorestore index from loaders.  By vectorstore index, this means 





## Example 2: Use LLMs with SQL to chat with the MIMIC-III database

Since we saw the limitations with one-hot encoding, a better approach would be to assign each word a unique integer.  The integer encoding for a specific word remains the same across all documents, so this will reduce the size of the corpus to unique words. 

To do this, Keras (neural network library) provides a handy **Tokenizer() API** that can handle multiple documents.  For a deeper understanding of its implementation, see this [tutorial](https://machinelearningmastery.com/prepare-text-data-deep-learning-keras).


![](/assets/images/2023-09/output2.png)

## Conclusion

In this tutorial, we explored how to create word embeddings from scratch, using a neural network to perform a classification task.  By taking sample text from PubMed patient summaries, we were able to train a neural network to classify patients who had COVID-19 and those that did not.  In doing so, we were also able to train the embeddings, such that words with similar meanings were visually placed closer together.  

We can boost the performance of the training accuracy by adding in a different layer, such as a convolution layer.  I will explore these in future posts.


## References
+ <https://medium.com/technology-hits/overview-of-langchain-9f6362707cd0>
