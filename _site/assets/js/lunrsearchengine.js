
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about",
    "title": "About",
    "body": "Hi, I'm Sandy.  I am a cloud architect, data science and AI practitioner, and health informatics strategist.  This is a professional site to share my thoughts on the evolving landscape of technology in healthcare. My background spans nearly two decades in the healthcare/life sciences industry at Johnson &amp; Johnson, IBM Watson Health, Cloudera, and Microsoft.  I grew to love technology over the years, and my most memorable experiences have been creating solutions that delight and surprise.  I have been amazed by the recent advances in computing, and I dream of a future where these technologies can improve healthcare innovation and patient outcomes.  All views represented here are my own.                                                                                                                     "
    }, {
    "id": 2,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                                                   Encoding PubMed abstracts for NLP tasks                              :               Last month, I gave a talk at a local meetup on LLMs, LangChain &amp; SQL. Since then, I’ve wanted to explore the technical foundations of. . . :                                                                                                                                                                       Sandy                                27 Jul 2023                                                                                                                                                                                                                                                                                                                  When a correct diagnosis matters                              :               When does a correct diagnosis matter? Does it matter if a human or computer makes the decision? I reflect on a recent article by the. . . :                                                                                                                                                                       Sandy                                02 Jun 2023                                                                                                                      All Stories:                                                                                                     Advancing analysis of FDA Adverse Events using LLMs              :       Patient safety continues to be an issue in 2023, with nearly 1 in 4 patients experiencing an adverse event upon admission. Up to 40% of adverse events were related to. . . :                                                                               Sandy                17 Nov 2023                                                                                                                                     Switchover disruptions: The true cost of an AI scribe              :       “Switchover disruptions” were highlighted in Harvard Business Review’s recent article on the challenges of AI adoption in healthcare. Economists define it as the cost of integrating new technologies that can. . . :                                                                               Sandy                12 Oct 2023                                                                                                                                     Create word embeddings from PubMed patient summaries              :       Building upon the previous tutorial on one-hot encoding, this tutorial will explore the concept of word embeddings and implement this with real-world data. :                                                                               Sandy                14 Sep 2023                                                                                                                                     Should AI replace the hospital fax machine?              :       VC firm Andressen Horowitz recently published an article on how the latest AI technologies will have a big impact on healthcare. Is it finally time to say good-bye to the. . . :                                                                               Sandy                25 Aug 2023                                                                                                                                     Encoding PubMed abstracts for NLP tasks              :       Last month, I gave a talk at a local meetup on LLMs, LangChain &amp; SQL.  Since then, I’ve wanted to explore the technical foundations of LLMs, particularly neural networks. :                                                                               Sandy                27 Jul 2023                                                                                                                                     When a correct diagnosis matters              :       When does a correct diagnosis matter? Does it matter if a human or computer makes the decision? I reflect on a recent article by the Mayo Clinic on a diagnosis. . . :                                                                               Sandy                02 Jun 2023                                            "
    }, {
    "id": 4,
    "url": "http://localhost:4000/resources",
    "title": "Resources",
    "body": "A curated list of sites I follow across the healthcare and technology fields. HealthcareBecker's Hospital ReviewForbes HealthcareGround TruthsHealthcare InnovationHealthcare IT AnalyticsHealthcare IT NewsModern HealthcareStat News AI in HealthcareHugging Face for HealthKaggleNew England Journal of Medicine AIPapers With CodeStanford Center for Artificial Intelligence in Medicine and Imaging Data Science &amp; AIGoogle Machine Learning EducationMachine Learning MasteryTensorFlowTowards Data Science TechnologyArs TechnicaForbes Technology CouncilTechnopedia "
    }, {
    "id": 5,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 6,
    "url": "http://localhost:4000/advancing-analysis-fda-adverse-events-using-llms/",
    "title": "Advancing analysis of FDA Adverse Events using LLMs",
    "body": "2023/11/17 - Patient safety continues to be an issue in 2023, with nearly 1 in 4 patients experiencing an adverse event upon admission.  Up to 40% of adverse events were related to medications given in the hospital, underscoring the importance of post-market drug surveillance and sufficient bedside staffing. For the former, consumers and healthcare professionals are encouraged to report adverse events to the FDA.  The information is captured in the FDA Adverse Events Reporting System, which is used to improve product safety and protect public health.  In recent years, NLP has helped the FDA identify causal relationships between products and adverse events.  A recent initiative is now evaluating LLMs to improve efficiency and accuracy. From a technical lens, this was a topic I explored in my September talk on LLMs.  I covered 2 healthcare demos for using LLMs with LangChain, and LLMs with SQL databases. This tutorial will demonstrate using LLMs and LangChain to quickly summarize an adverse events report. Prerequisites:  Basic knowledge of OpenAIEnvironment:  Python: 3. 11. 6 OS: MacOS 12. 7. 1 VS Code: 1. 84. 1All resources can be found here. Generate an ADE report: Individual Case Reports for adverse events are typically requested through the FDA.  A sample report is shown below:  For the purpose of this tutorial, I used OpenAI’s ChatGPT (GPT-3. 5) to generate a synthetic adverse events report.  I chose warfarin, as it is in the class of drugs that have resulted in serious adverse drug reactions. These were the series of prompts I used to generate the final report: “Create an adverse event report for warfarin that is submitted to the FDA”“Fill out the report with hypothetical information”“Remove the placeholders [ ]”“Rewrite the event as a narrative, not a list” A snippet of the report is below:  On November 10, 2023, Mr. John Doe, a 65-year-old male with a medical history of hypertension and atrial fibrillation, was brought to our attention at ABC Medical Center. The patient had been prescribed warfarin (5 mg daily) for his atrial fibrillation. Q&amp;A application overview: This LangChain blog post provides a high-level overview for building a Q&amp;A application. The main steps include:  Load documents Split documents into chunks Create embedding vectors from chunks Store vectors in vector database Retrieve relevant documents from database Pass relevant documents to LLM LLM generates final answerIngest Data: Query Data: Set the OpenAI API Key: Navigate to OpenAI to obtain the API Key.  This will be needed to authenticate requests to the API. 1234# set API keys to authenticate requests to the APIAPI_KEY = '&lt;API Key&gt;'os. environ[ OPENAI_API_KEY ] = API_KEYUse LangChain to load documents into a vector store: LangChain is a framework for developing applications powered by LLMs.  The main idea is that developers can “chain” different components around an LLM to create more powerful use cases. Hence, we can connect LLMs to documents. LangChain has many different methods to load documents.  TextLoader is used to load in a text document and create a vector representation using the VectorStoreIndexCreator: 12345# load text documentloaders = TextLoader('&lt;path to text document&gt;')# create a vector representation of the loaded documentindex = VectorstoreIndexCreator(). from_loaders([loaders])The VectorStoreIndexCreator handles steps 2-4 above (chunking, embedding, and storage).  This article goes into more detail about the class, including customization. The default settings to note are:  Chunking - uses RecursiveCharacterTextSplitter() to divide text at specific characters Embedding - uses OpenAIEmbeddings to generate embeddings Storage - embeddings are stored in Chroma, an open-source vector storeSet up Streamlit app: With Streamlit, we set up a simple web app to allow users to ask questions of the document: 123# display the page title and the text box for the user to ask the questionst. title('🦜 LangChain: Chat with Adverse Events Report')prompt = st. text_input( Enter your question )Query the vector store: When a user passes in a question, the store is queried to retrieve the data that is ‘most similar’ to the embedded query. 123456# get response from LLMif prompt: response = index. query(  llm=ChatOpenAI(model_name= gpt-3. 5-turbo , temperature=0. 2),   question = prompt,   chain_type = 'stuff')Under the hood, we pass in the ChatOpenAI model (gpt-3. 5-turbo) and set the temperature.  The temperature controls the randomness of the output generated (closer to 1 will generate a more creative response).  chain_type = ‘stuff’ combines the question and relevant document chunks into a single prompt to pass to the LLM. This visual shows the overall workflow:  Let’s summarize: With Streamlit running, we prompt the document by asking a question followed by a summarization task: Conclusion: In this tutorial, we explored using LLMs and LangChain to retrieve information from an adverse events report.  LangChain is a framework for building LLM-based applications, such as a chatbot.  Although NLP is not new, I was surprised by the ease of using natural language prompts to retrieve information.  I think LLMs can make adverse events analysis more efficient, and improve product safety. It would be interesting to test out LLMs on different types of documents (i. e. , Standards of Care), and build out an advanced UI with Streamlit. I will explore these in a future post. References:  https://www. nbcnews. com/health/health-news/nearly-1-4-us-hospital-patients-experience-harmful-event-study-finds-rcna65119 https://www. fda. gov/drugs/surveillance/questions-and-answers-fdas-adverse-event-reporting-system-faers https://www. lifescienceleader. com/doc/how-the-fda-views-natural-language-processing-0001 https://www. fda. gov/about-fda/nctr-research-focus-areas/bertox-initiative https://openai. com/ https://www. ncbi. nlm. nih. gov/books/NBK519025/ https://github. com/hwchase17/chat-your-data/blob/master/blogpost. md https://python. langchain. com/ https://medium. com/@kbdhunga/enhancing-conversational-ai-the-power-of-langchains-question-answer-framework-4974e1cab3cf https://streamlit. io/"
    }, {
    "id": 7,
    "url": "http://localhost:4000/switchover-disruptions-true-cost-ai-scribe/",
    "title": "Switchover disruptions: The true cost of an AI scribe",
    "body": "2023/10/12 - “Switchover disruptions” were highlighted in Harvard Business Review’s recent article on the challenges of AI adoption in healthcare.  Economists define it as the cost of integrating new technologies that can dampen an organization’s profits. This prompted me to examine the ways in which this next wave of AI (Large Language Models/LLMs) can minimize such disruptions, and if this type of AI is worth the tradeoff. The unsettling case of high switchover disruption: EHRs: I was fascinated by the article’s comparison of 2 new technologies that arrived in healthcare: EHRs (2009) vs. a new surgical technique to remove the gallbladder (1988).  EHRs faced strong resistance, until the Obama administration stepped in to incentivize organizations to go digital.  In contrast, the new (minimally invasive) surgical technique faced low switchover disruption - physician adoption was easier and limited to surgeons. The key? Hospitals and surgeons were already in the business of doing the procedure. EHRs should have been an easy win.  Why wouldn’t a patient want to see all their medical information stored in one place? Why wouldn’t a physician want to see a more complete view of their patient’s health? In all other industries where digitization has led to improved efficiency, the complete opposite happened with EHRs.  Perhaps we were not aligned on improving healthcare outcomes after all. I agree that the issue came down to control.  Not surprisingly (in a capitalist society), there are power struggles between physicians, payers, and government.  But guess who loses out in the end? The patient. Will the same fate await this next wave of AI? A plausible use case: AI Medical Scribe: The arrival of ChatGPT has created a dizzying revival for using AI in healthcare, with the promise of automated diagnosis and treatments.  This, by the way, were the same statements touted by IBM Watson a decade ago.  Granted, today’s AI technology has improved over its predecessors, it doesn’t matter unless it can prove its business value.  Martin Kohn, the former IBM Research chief medical scientist, stated:  “Prove to me that it will actually do something useful—that it will make my life better, and my patients’ lives better. ” I believe AI systems can do something useful - work as a AI medical scribe.  Although this is less glamorous than diagnosing and treating patients, this is probably the best use case for AI today.  Case in point: One of the ill by-products of digitization has been increased administrative burden placed upon healthcare providers.  If technology can reduce this burden by summarizing patient information or answering patients efficiently, providers will have more face-to-face time with patients, and increase productivity.  For example, JAMA reported that ChatGPT provided comparable quality and empathetic responses to patient questions found in an online forum (vs. physicians). I think more physicians and health system leaders will be on board with these AI technologies, as efficiency is one key to improving organizational performance (i. e. , reduced costs, better patient outcomes) and potential profits. The true cost of running LLMs: While LLMs have demonstrated remarkable performance in terms of human comprehension, one must also consider the cost to run them.  They are not cheap, due to the amount of data they can ingest and the compute power required to process the data.  The Wall Street Journal ran a piece earlier this month on the struggles for tech giants to monetize these technologies.  According to the article, Microsoft is using OpenAI’s latest version (GPT-4) software for its AI features.  However, that version is the largest and most expensive model available. Equally important is understanding the technology’s impact on the environment.  According to this op-ed from Ars Technica, the most expensive and proprietary (“black box”) models are reserved for very deep pocketed organizations.  As such, building and deploying these models “requires a lot of planetary resources: rare metals for manufacturing GPUs, water to cool huge data centers, energy to keep those data centers running 24/7 on a planetary scale… all of these are often overlooked in favor of focusing on the future potential of the resulting models. ” What’s the right ROI then? Would it behoove healthcare organizations to use smaller, open-source LLMs? A lack of privacy standards should be of upmost concern, and will likely push organizations to move towards proprietary LLMs.  However, it might be overkill to use the likes of GPT-4 and beyond to answer patient questions.  Perhaps the sweet spot could lie with patient summarization and triaging tasks.  One must consider the tradeoff in terms of time/cost for leveraging human labor vs. a turbo-charged AI chatbot. Conclusion: This article provided useful insights and recommendations to overcome the challenges of AI adoption in healthcare.  The challenges were no different a decade ago with EHR adoption, and it was very interesting to understand the power dynamics that made adoption difficult.  While there are no clear answers yet, these next-gen AI technologies have seen a bit more acceptance by the healthcare community.  However, I think it remains to be seen how far-reaching this technology will be, with a medical scribe sounding like a safe bet. "
    }, {
    "id": 8,
    "url": "http://localhost:4000/create-word-embeddings-pubmed-patient-summaries/",
    "title": "Create word embeddings from PubMed patient summaries",
    "body": "2023/09/14 - Building upon the previous tutorial on one-hot encoding, this tutorial will explore the concept of word embeddings and implement this with real-world data. For our example, we extract patient summaries from PubMed and label those that had COVID-19 vs. not COVID-19.  Word embeddings are created from text, and the embeddings are trained as part of a neural network to perform a classification task.  Through training, the computer will learn word relationships. Pre-requisites:  Basic knowledge of neural networks Azure Data Studio Docker Python 3. 10. 3 SQL Server on Mac (on-prem)All resources can be found here. A short intro to Word Embeddings: Word Embeddings were a bit of a complex concept to grasp, until I got into the weeds of building one.  I’ve come to appreciate that they are an important concept in deep learning, for the reason that word meanings can be approximated mathematically. To best understand the intuition behind word embeddings, I highly recommend reading this blog post from Christopher Olah. There are a number of techniques available to build a word embedding, including using pre-trained embeddings generated by GloVe, word2vec, etc.  In this tutorial, we will build an embedding from scratch. Let’s get data: I selected a dataset of ~167K PubMed patient summaries via HuggingFace.  The data is loaded into SQL Server on a Mac. Start SQL Server via the terminal, giving the username and password: 1$ mssql -u &lt;sql server username&gt; -p &lt;sql server password&gt;Connect SQL Server to Azure Data Studio to query the data. Attached is a screenshot to modify the columns before importing the data: Run the below query to return the first 100 records and save as csv. 1234567891011SELECT TOP (100) [patient_id] ,[patient_uid] ,[PMID] ,[file_path] ,[title] ,[patient] ,[age] ,[gender] ,[similar_patients] ,[relevant_articles]FROM [test]. [dbo]. [PMC-Patients]Define class labels: Since this is a binary classification task, we will label the dataset as:  patients with COVID-19 = ‘1’ patients without COVID-19 = ‘0’123456789101112131415labels = []df['label'] = ''for index, row in df. iterrows():  if 'COVID-19' in row['patient']:    row['label'] = '1'  else:    row['label'] = '0'   labels. append(row['label'])labels_arr = np. array(labels). astype(float)print(labels_arr)12345[1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. ]Create a corpus: Now that we have our labeled dataset, we create a corpus.  We take the 1st sentence from each document.  A sample of the first 3 documents is below: 1234['This 60-year-old male was hospitalized due to moderate ARDS from COVID-19 with symptoms of fever, dry cough, and dyspnea. ', 'We describe the case of a 55-year-old male who presented to the emergency department via emergency medical services for the chief complaint of sudden onset shortness of breath that woke him from his sleep just prior to arrival. ', 'A 20-year-old Caucasian male (1. 75 m tall and 76 kg (BMI 24. 8)), was admitted to the medical department for persistent hyperpyrexia, severe sore throat, dyspnea, and impaired consciousness with stupor. , . . . ]For 100 documents, there are 2541 total words in the corpus. Convert text to integers: Since we saw the limitations with one-hot encoding, a better approach would be to assign each word a unique integer.  The integer encoding for a specific word remains the same across all documents, so this will reduce the size of the corpus to unique words. To do this, Keras provides a handy Tokenizer() API that can handle multiple documents.  For a deeper understanding of its implementation, see this tutorial. 123456789101112131415161718# integer encode words per document encod_corp = []# fit tokenizer on docst = Tokenizer(filters='! #$%&amp;()*+,/:;&lt;=&gt;?@[\\]^_`{|}~\t\n')t. fit_on_texts(corp) encod_corp = t. texts_to_sequences(corp)# get unique wordsvocab = t. word_index# print vocab listprint( vocab: )for i,v in enumerate(vocab, 1):  print(i,v)vocab_size = len(vocab) print('Vocab size = %s unique words' % vocab_size)12345678vocab:1 a2 of3 with4 and5 theVocab size = 931 unique wordsOut of 2541 total words, 931 unique words are found. Pad the documents: Keras requires that all documents must be the same length.  We find the maximum length of a document, which is 55 words.  Zeroes are then added to the shorter documents using the pad_sequences function: 1234# pad the documents with zerospad_corp=pad_sequences(encod_corp,maxlen=maxlen,padding='post',value=0. 0)print(pad_corp)12345[[ 31 281 10  7 160 44  6 282 283 28 54  3 84  2 29 45 36  4 161  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]  . . . The above array represents the text of Document 1. Create an embedding: To create the embedding, we create a Keras Sequential model.  Sequential means that each layer in the network has exactly one input and one output.  To define the embedding, we need 3 inputs:  input_dim: size of vocabulary output_dim: embedding dimension input_length: maximum length of a documentA output_dim = 2 means that every vocabulary word is represented by a vector that contains 2 elements, or features.  These numbers can be chosen arbitrarily.  A larger output_dim will have more features to train on, but will also be more computationally expensive. Once the embedding layer is added to the network, the learning process is configured, and we run model. predict() to generate the predicted outputs. We can also add other hidden layers (Flatten, Dense) to discover more complex patterns in the data.  These will be discussed once we train the embeddings. 12345678910111213141516171819202122# create keras modelmodel = Sequential()# define embeddingembedding_layer = Embedding(            input_dim=vocab_size+1,            output_dim=2,             input_length=maxlen)# add layersmodel. add(embedding_layer)model. add(Flatten()) model. add(Dense(1, activation='sigmoid'))# configure the learning processmodel. compile(    optimizer='adam',    loss='categorical_crossentropy',     metrics=['accuracy'])# model predictionembedding_output = model. predict(pad_corp)Visualize intial embeddings: The embedding layer is a lookup table, which represents each word as floating point values (weights) in the dimension specified.  These weights are initialized randomly before training the model.  The weights can be obtained as follows: 123456# embedding layerembedding_layer = model. get_layer(index=0)embedding_layer_weights = embedding_layer. get_weights()[0]print(embedding_layer_weights)Since the output_dim = 2, the embedding_layer_weights consists of each word represented by 2 weights: 12345678910[[ 7. 04301521e-03 3. 39607336e-02] (index 0) [ 4. 43325080e-02 -4. 35174219e-02] --&gt; 'a' [-1. 84080116e-02 -4. 48269024e-02] --&gt; 'of' [-4. 74609025e-02 4. 29279730e-03] --&gt; 'with' [ 1. 24161355e-02 4. 76875566e-02] --&gt; 'and' [-1. 89721715e-02 -2. 00293791e-02] --&gt; 'the' [-2. 18192935e-02 -4. 75601330e-02] --&gt; 'to' [-2. 51929164e-02 -9. 96438414e-03] --&gt; 'was'. . . ]]The embedding_output is the result of the embedding layer for a given input sequence.  For Document 1, we see that each value from the embedding layer is mapped to a word in that document: 12345678[[[ 2. 08440907e-02 3. 52325179e-02] --&gt; 'This' [-1. 70833841e-02 -4. 37318459e-02] --&gt; '60-year-old' [-4. 54872735e-02 1. 42193772e-02] --&gt; 'male' [-2. 51929164e-02 -9. 96438414e-03] --&gt; 'was' [-4. 34226505e-02 -2. 67695189e-02] --&gt; 'hospitalized' [-3. 18809636e-02 3. 46260779e-02] --&gt; 'due' [-2. 18192935e-02 -4. 75601330e-02] --&gt; 'to' . . . ]]]Let’s see how this looks visually.  Since these embeddings are not trained, it would make sense that the words are fairly scattered: Visualize trained embeddings: After adding the embedding layer, we have a 55 x 2 (doc length x embedding dimension) matrix.  We need to compress (flatten) this into a 1D vector, to send to the next hidden (dense) layer. As shown above, we add the Flatten and Dense layers to the model. Summary of layers: 1234567891011121314_________________________________________________________________ Layer (type)        Output Shape       Param #  ================================================================= embedding_28 (Embedding)  (None, 55, 2)       1864                                    flatten_17 (Flatten)    (None, 110)        0                                      dense_17 (Dense)      (None, 1)         111                                    =================================================================Total params: 1975 (7. 71 KB)Trainable params: 1975 (7. 71 KB)Non-trainable params: 0 (0. 00 Byte)_________________________________________________________________The 55×2 matrix is now reduced to a 110-element vector by the Flatten layer. Finally, we train the model on the classification task and evaluate its performance. 12# fit the modelmodel. fit(pad_corp, labels_arr, epochs=50, verbose=1)123# evaluate the modelloss, accuracy = model. evaluate(pad_corp, labels_arr, verbose=1)print('Accuracy: %f' % (accuracy*100))124/4 [==============================] - 0s 2ms/step - loss: 0. 0000e+00 - accuracy: 0. 8900Accuracy: 88. 999999Since these embeddings are now trained, we can visualize more defined clusters with ~89% accuracy for the prediction task.  Conclusion: In this tutorial, we explored how to create word embeddings from scratch, using a neural network to perform a classification task.  By taking sample text from PubMed patient summaries, we were able to train a neural network to classify patients who had COVID-19 and those that did not.  In doing so, we were also able to train the embeddings, such that words with similar meanings were visually placed closer together. We can boost the performance of the training accuracy by adding in a different layer, such as a convolution layer.  I will explore this in a future post. References:  http://colah. github. io/posts/2014-07-NLP-RNNs-Representations https://huggingface. co/datasets/zhengyun21/PMC-Patients/tree/main https://builtin. com/software-engineering-perspectives/sql-server-management-studio-mac https://www. sqlshack. com/sql-server-data-import-using-azure-data-studio/ https://keras. io/ https://machinelearningmastery. com/prepare-text-data-deep-learning-keras https://machinelearningmastery. com/use-word-embedding-layers-deep-learning-keras https://cs229. stanford. edu/summer2020/cs229-notes-deep_learning. pdf https://github. com/keras-team/keras/issues/3110"
    }, {
    "id": 9,
    "url": "http://localhost:4000/should-ai-replace-hospital-fax-machine/",
    "title": "Should AI replace the hospital fax machine?",
    "body": "2023/08/25 - VC firm Andressen Horowitz recently published an article on how the latest AI technologies will have a big impact on healthcare.  Is it finally time to say good-bye to the trusted fax machine? I read with guarded optimism, given AI’s lack of success in healthcare over the last decade and during the COVID-19 pandemic.  While I see great potential, I do not believe AI to have as much impact in a field where human connection and privacy is vital. Less (cumbersome) software, more productivity: I love new technology.  I love it because it makes me more productive.  As I was booking holiday travel recently, I realized how easy it has become to do things on my own - on my own time, in my own way.  No calling a travel agent to arrange a trip.  No taking out a paper map to get to the hotel.  I don’t think you’ll find too many people who will complain about the convenience this provides. We use new software all the time these days.  Everytime a new app comes out, we can easily download it and check it out.  It integrates seamlessly into our everyday lives; it makes things a bit more efficient. Unfortunately, healthcare seems to have gotten it backwards -every new healthcare software solution promises more productivity, but instead does the opposite.  EHRs require more clicks for physicians.  For patients, my personal favorite is when I am asked to fill out insurance information in the EHR before my next appointment, even though I provided it at the previous appointment.  So, why bother filling out anything online? That’s not productivity. The article states that instead of healthtech companies developing new software, they’ll develop “AI ‘people’ who are cheap, fast, cheerful and empathic. ” However, if I’m a patient, I want a human being to help me feel better.  The thought of a machine having empathy discounts any reason to see a doctor at all. A good piece of software is one that will handle the simple things like document capture, reconciliation, etc.  I agree with the article that the first revolution will be non-clinical use cases.  If AI can help us get past that hurdle, then I think we will have achieved productivity. Marginal improvements are worth the effort: Having worked in high-tech technical roles over the last decade, I have seen the evolution of more advanced computing capabilities.  Working in big data and cloud platforms have shown the ability to create powerful solutions with seemingly limitless compute power.  I may even argue that next-gen AI solutions and the infrastructure that powers them will produce 10x the value that will displace outdated technologies. Hence, replace the humble fax machine. Yet, I am wary about moving at that pace in healthcare.  On the one hand, cloud computing can process billions of data points for genomic sequencing or population health management.  The article is correct in that AI will require more compute resources due to algorithm complexity and compute resources required.  There will be more insights, more personalization, more productivity. But there could also be a cloud outage, a malicious entity that wants to conduct a cybersecurity attack on a hospital, a patient record that ends up in the wrong hands. There’s nothing wrong with marginal improvements.  Is it better to misdiagnose 1 patient or 1000 patients? A small error allows time to investigate and course correct. A world-class AI doctor in your pocket: Do I really want one?: Good technology works seamlessly and increases productivity.  Much like today’s travel apps, it would be amazing to have a doctor that knows everything about me in the future.  There are some models already out there that attempt this - Livongo by Teladoc, as an example.  However, even if it is covered by insurance, I haven’t really used it unless out of necessity. An AI doctor might sit as one of those unused apps on my phone.  Most people can find a satisfactory answer to a medical question via an internet search, coupled with an in-person visit to the doctor’s office.  Can an AI doctor change things for the better? Maybe.  However, a virtual doctor will never replace a conversation with a real human being. However, I like the idea of AI enabling earlier diagnosis - this is one use case I believe will see more rapid adoption. Conclusion: I appreciated this insightful and hopeful article for the future of healthcare.  Perhaps with this new wave of AI, there is a renewed commitment by people and processes to enable a better healthcare experience for everyone.  Perhaps we can put that fax machine to rest. "
    }, {
    "id": 10,
    "url": "http://localhost:4000/encoding-pubmed-abstracts-nlp-tasks/",
    "title": "Encoding PubMed abstracts for NLP tasks",
    "body": "2023/07/27 - Last month, I gave a talk at a local meetup on LLMs, LangChain &amp; SQL.  Since then, I’ve wanted to explore the technical foundations of LLMs, particularly neural networks. This article will begin a series of technical tutorials that are geared towards healthcare care use cases.  While there is no shortage of resources to learn about LLMs, neural networks, or the latest ML algorithms, my focus will be to reinforce technical concepts related to deep learning. A simple approach to NLP - one-hot encoding: To start, I wanted to backtrack the origins of LLMs, which are a type of neural network.  A neural network is a type of machine learning approach that attempts to mimic the way the brain works (biological neural network).  This approach has been shown to perform better on NLP tasks than previous methods.  For a great overview of NLP, check out this guide. The goal of NLP is to enable computers to “understand” natural language in order to perform some task, such as sentiment analysis.  In order to do so, natural language (text) has to be converted (encode) into a numerical format. There are numerous approaches to encode text, with more advanced approaches surfacing over the years.  I will start with one-hot encoding, as it is one of the most familiar data pre-processing techniques for ML.  However, we will also begin to see the limitations of such a technique through the example below. For NLP, one of the simplest techniques for encoding text is to represent each categorical variable (a word) as a binary vector.  A one-hot vector can be thought of as a type of binary vector where the index of the word is denoted as ‘1’, and all other words are denoted as ‘0’.  The size/dimension of the vector is determined by the total number of unique words (vocabulary) found in the text. Consider the following text: ‘I have a fever’.  The vocabulary consists of 4 unique words (I, have, a, fever), and each word is represented as a one-hot vector.  Let’s convert a few PubMed abstracts to one-hot vectors: To put the above tutorial into practice, I thought I would give this a try with a few abstracts.  Let’s say that we want to perform an NLP task on papers that discuss cardiovascular disease (CVD) risk factors.  This is what my query and results look like in PubMed: Each abstract represents a single document in a corpus (collection of documents).  Let’s take the first 5 words from each abstract.  For simplicity purposes, we will ignore header terms such as ‘Context’, ‘Introduction’, ‘Purpose’.  There are 15 words in the corpus:  Doc 1: “The difference between actual and”Doc 2: “Cardiovascular disease (CVD) is a”Doc 3: “To evaluate awareness about cardiovascular” Next, we need to find the unique words.  We have 14 unique words (‘cardiovascular’ is repeated twice):  Doc 1: The(1) difference(2) between(3) actual(4) and(5)Doc 2: Cardiovascular(6) disease(7) (CVD)(8) is(9) a(10)Doc 3: To(11) evaluate(12) awareness(13) about(14) cardiovascular(6) We represent these unique words in a vocabulary:  Vocabulary = {‘The’, ‘difference’, ‘between’, ‘actual’, ‘and’, ‘Cardiovascular’, ‘disease’, ‘(CVD)’, ‘is’, ‘a’, ‘To’, ‘evaluate’, ‘awareness’, ‘about’} Each word is represented as a one-hot vector with a length equal to the size of the vocabulary (N = 14).  We will have something that looks like this: Limitations of one-hot encoding: One challenge seen with the one-hot encoding approach is that there is no information about the words the vectors represent, or how the words relate to each other. That is, it tells us nothing about the similarities or differences between words.  If we were to graph each vector and calculate a similarity measure (e. g. , cosine similarity) between them, we would see that there is 0 similiarity between any two vectors.  Refer to this article for a mathematical overview of the concept. A second challenge is sparse, highly dimensional data.  When each word in a document is replaced with a one-hot vector, we start to get a large feature space with a lot of zeroes.  In fact, when increase our vocabulary size (for example, double the vocabulary size N = 28 words), the feature space will morph into something like this: This dataset is:  sparse (majority of the elements are zeroes) highly-dimensional (a larger vocabulary creates a larger feature space, which requires more computational power and data) hard-coded (machine does not learning anything from the data)Given these limitations, this technique makes it difficult for a computer to detect any sort of meaningful patterns to make an accurate prediction. Conclusion: In this tutorial, we explored one-hot encoding, a very simple way to convert categorical variables for natural language processing tasks.  By taking a subset of PubMed abstracts, we were able to see how this approach becomes highly inefficient with larger vocabularies.  Some of these inefficiencies are due to a lack of understanding relationships between words, as well as a sparse and highly-dimensional feature space. There have been different techniques that have improved upon the limitations of one-hot encoding, and they have worked increasingly well with neural networks.  I will explore these in future posts. References:  https://www. deeplearning. ai/resources/natural-language-processing https://web. stanford. edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1. pdf https://developers. google. com/machine-learning/glossary#one-hot-encoding https://www. tensorflow. org/text/guide/word_embeddings https://medium. com/intelligentmachines/word-embedding-and-one-hot-encoding-ad17b4bbe111 https://builtin. com/data-science/curse-dimensionality https://towardsdatascience. com/word-embeddings-intuition-behind-the-vector-representation-of-the-words-7e4eb2410bba https://wordcount. com/"
    }, {
    "id": 11,
    "url": "http://localhost:4000/when-correct-diagnosis-matters/",
    "title": "When a correct diagnosis matters",
    "body": "2023/06/02 - When does a correct diagnosis matter? Does it matter if a human or computer makes the decision? I reflect on a recent article by the Mayo Clinic on a diagnosis concluded by ChatGPT vs. cardiologist, and its implications for patient care. Over the last few months, I have been following the tech news closely as new AI technologies, particularly Large Language Models (LLMs) and ChatGPT (a type of LLM), have exploded on to the scene.  Of course, being a bit skeptical, I was curious to see how this next iteration of AI would fare in healthcare. Putting LLMs to the test: In their article When Physicians Go Head-to-Head with Large Language Models, John Halamka, MD, and his team at the Mayo Clinic Platform sought to evaluate these latest technologies.  They prompted ChatGPT with the following patient presentation:  “Mr. Jones, 59 years old, with a history of hypertension, stroke, and elevated lipid levels, arrives in the ED complaining of sudden-onset intense substernal chest pain that radiates to his left leg but does not affect his left arm or jaw. He also has an elevated troponin I level. What is the correct diagnosis?” ChatGPT replied:  “Based on the symptoms and medical history provided, Mr. Jones is presenting with a potential myocardial infarction (MI), also known as a heart attack. The sudden onset of intense substernal chest pain that radiates to his left leg is a common symptom of a heart attack. The fact that the pain does not affect his left arm or jaw is not unusual, as some heart attacks can present with atypical symptoms. ” From a layman’s perspective, this answer seems pretty convincing.  From a technological perspective, this is pretty impressive that ChatGPT can predict the next series of words or “tokens” based on a prompt, and return results that sound surprisingly human. The case for human diagnostic reasoning: Herein lies the problem - just because we have a highly probablistic AI system doesn’t mean it translates well into clinical practice.  The article goes on to compare ChatGPT’s answer to a cardiologist who encountered an identical patient scenario:  Based on a methodical review of all the patient data, Dr. Schleifer et al. questioned the significance of the patient’s radiating left leg pain. One of the hallmarks of a genuine expert diagnostician is their more completely developed disease scripts and their ability to spot inconsistencies that don’t fit into these scripts. The leg pain was one of those clues that might warrant a walk down a different diagnostic path.  They also used a reasoning technique sometimes referred to as pre-mortem examination. Essentially, they asked themselves: What would happen once a specific diagnosis is made and acted upon? What are the consequences, good and bad? In the case of Mr. Jones, if he is treated with the anticoagulants usually indicated for a typical MI, and he actually had another condition such as an aortic dissection, the consequences could prove disastrous. Which response is more reassuring?: Taking a step back and looking at the responses of ChatGPT vs. cardiologist, I thought about which one would resonate more if I were a patient. Let’s think about this - if you ever find yourself in the emergency room, physicians will conduct a battery of tests before coming to a conclusion.  I appreciate the pre-mortem examination technique, as it forces one to think about the implications of a specific diagnosis.  I wouldn’t want my doctor to draw a conclusion based on what an AI system said, but that they would do a full workup to confirm their hypothesis. In all fairness though, ChatGPT did close out its response as follows:  It is important to note that a definitive diagnosis can only be made by a healthcare professional after conducting a thorough medical evaluation, including a physical examination, ECG, and other tests as necessary. ” I think this response is fine.  However, if a more accurate conclusion was made by human being, then what is the value of using this system if it is going to add more minutes to a clinical workflow? A correct diagnosis matters in all cases, but more common cases may be automated: One thing to note is that LLMs are limited by their tendency to hallucinate.  It means that a generative AI system can output novel text that sound completely plausible, but are factually incorrect.  Currently, there are more focused LLMs trained on the medical domain that are under development, with the idea that narrower models may mitigate these hallucinations. Despite these limitations, I agree with the authors that LLMs still have value in healthcare.  My key takeaways:  ChatGPT may be better suited to situations where common medical conditions are seen and have a standard treatment plan (i. e. , primary care) Automating common cases can free up physician time for more complex cases or other tasks In complex clinical cases, employing human reasoning and intuition can mean life or death for a patientLastly, I would argue that most physicians aim to establish a trust relationship with their patients, mutually working towards the best possible outcome.  This type of relationship fails to exist between a human and a computer. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});